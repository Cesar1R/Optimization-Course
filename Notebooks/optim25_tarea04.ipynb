{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Curso de Optimización \n",
    "## Tarea 4\n",
    "\n",
    "| Descripción:                         | Fechas                 |\n",
    "|--------------------------------------|------------------------|\n",
    "| Fecha de publicación del documento:  | **Febrero 25, 2025**   |\n",
    "| Fecha límite de entrega de la tarea: | **Marzo    4, 2025**   |\n",
    "\n",
    "\n",
    "### Indicaciones\n",
    "\n",
    "- Envie el notebook con los códigos y las pruebas realizadas de cada ejercicio.\n",
    "- Si se requiren algunos scripts adicionales para poder reproducir las pruebas,\n",
    "  agreguelos en un ZIP junto con el notebook.\n",
    "- Genere un PDF del notebook y suba el archivo por separado, sin comprimirlo, \n",
    "  para anotar la evaluación y comentarios de cada ejercicio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resuelto por Cesar Amilkar Rivera Covarrubias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Ejercicio 1 (1 puntos)\n",
    "\n",
    "1. Muestre que los eigenvectores de una matriz $\\mathbf{A}$ simétrica y definida positiva \n",
    "   forman un conjunto de direcciones conjugadas respecto a la matriz $\\mathbf{A}$.\n",
    "\n",
    "### Solución:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sea $A$ una matriz simetrica y definida positiva. Dados dos vectores $u$ y $v$ asociados a los eigenvalores $ \\alpha$ y $\\beta$, respectivamente, tales que $\\alpha \\neq \\beta$. Veamos que \n",
    "\n",
    "$$ (v^T A u)^T  = u^T A v, $$\n",
    "\n",
    "notemos que $v^T A u = (v^T A u)^T$ pues el producto es un número real. Luego, \n",
    "\n",
    "$$\n",
    "v^T A u  = v^T \\alpha u = \\alpha v^t u, \n",
    "$$\n",
    "\n",
    "además \n",
    "\n",
    "$$\n",
    "u^T A v = u^t \\beta v = \\beta u^t v.\n",
    "$$\n",
    "\n",
    "\n",
    "Por lo mencionado anteriormente, tenemos que \n",
    "\n",
    "$$\n",
    "\\alpha v^t u = \\beta u^t v \\Rightarrow (\\alpha - \\beta) u^t v, \n",
    "$$\n",
    "\n",
    "la hipotesis nos permite concluir que el producto anterior es cero, del teorema espectral se cumple que $u \\perp v$. Así, obtenemos que para cuales quiera dos eigenvectores $u$ y $v$ asociados a diferentes eigenvalores se cumple que \n",
    "\n",
    "$$ u^T A v = 0, $$ \n",
    "\n",
    "formando yun conjunto de direcciones conjugadas respecto a la matriz A. Como queriamos probar. \n",
    "\n",
    "Notemos que no es posible garantizar lo anterior si los eigenvectores $u$ y $v$ estan asociados al mismo eigenvalor, ya que el teorema espectral no nos garantiza que $u \\perp v$\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```\n",
    "\n",
    "\n",
    "```\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 2 (9 puntos)\n",
    "\n",
    "Programe el método de gradiente conjugado lineal, Algoritmo 2 de la Clase 11,\n",
    "para minimizar la función cuadrática \n",
    "   \n",
    "$$ f(\\mathbf{x}) = \\frac{1}{2} \\mathbf{x}^\\top\\mathbf{A}\\mathbf{x}-\\mathbf{b}^\\top\\mathbf{x},  $$ \n",
    "  \n",
    "donde $\\mathbf{A}$ es una matriz simétrica y definida positiva.\n",
    "\n",
    "1. La función que implementa el algoritmo recibe como entrada la matriz\n",
    "   $\\mathbf{A}$, el vector $\\mathbf{b}$, el punto inicial $\\mathbf{x}_0$,\n",
    "   el número máximo de iteraciones $N$ y una tolerancia $\\tau>0$.\n",
    "   Haga que la función devuelva el último punto  $\\mathbf{x}_k$, \n",
    "   el último residual $\\mathbf{r}_k$, el número de iteraciones $k$ \n",
    "   y una variable binaria $bres$ que indique si se cumplió que $\\|\\mathbf{r}_k \\|<\\tau$\n",
    "   ($bres=True$) o no ($bres=False$).\n",
    "\n",
    "2. Pruebe el algoritmo con las matrices y vectores usadas en la Tarea 2.\n",
    "\n",
    "- Lea cada  archivo `npz` para obtener  $\\mathbf{A}$ y el vector $\\mathbf{b}$.\n",
    "- Defina $n$ como el tamaño del arreglo $\\mathbf{b}$.\n",
    "- Use $n$ como el máximo número de iteraciones para el algoritmo.\n",
    "- Defina $\\mathbf{x}_{0} = (-5, 0, ..., 0)^\\top$ de dimensión $n$ y la tolerancia\n",
    "  $\\tau = \\sqrt{n\\epsilon_m}$,  donde $\\epsilon_m$ es el épsilon máquina.\n",
    "\n",
    "Para archivo de prueba imprima los siguientes datos\n",
    "\n",
    "- la dimensión $n$,\n",
    "- el  número $k$ de iteraciones realizadas,\n",
    "- las primeras y últimas 3 entradas del punto $\\mathbf{x}_k$ que devuelve el algoritmo,\n",
    "- la norma del residual $\\mathbf{r}_k$, \n",
    "- la variable $bres$ para saber si el algoritmo puedo converger.\n",
    "- El número de condición de la matriz $\\kappa_2(\\mathbf{A}) = \\lambda_{\\max}/\\lambda_{\\min}$,\n",
    "  donde $\\lambda_{\\max}$ es el eigenvalor más grande de la matriz y $\\lambda_{\\min}$\n",
    "  es el eigenvalor más pequeño.\n",
    "  \n",
    "3. Compare estos resultados con los obtenidos en el Ejercicio 2 de la Tarea 3\n",
    "   con el método de descenso máximo con paso exacto y escriba un comentario\n",
    "   al respecto.\n",
    "\n",
    "### Solución:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from funciones_prop import *\n",
    "\n",
    "eps = np.finfo('float').eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradiente_conjugado (A, b, x0, N, tol = eps):\n",
    "\n",
    "    n = len(A)\n",
    "    rk = A@x0 - b \n",
    "    pk = -rk\n",
    "    xk = x0.copy()\n",
    "\n",
    "    for i in range(N+1):\n",
    "        \n",
    "        if np.linalg.norm(rk) < tol: \n",
    "            return xk, rk, i+1, True\n",
    "            \n",
    "        alpha_k = (rk.T @ rk) / (pk.T @ A @ pk)\n",
    "        xk = xk + alpha_k * pk \n",
    "        rk_new = rk + alpha_k * (A @ pk)\n",
    "\n",
    "        beta_k = (rk_new.T @ rk_new) / (rk.T @ rk) \n",
    "\n",
    "        pk = -rk_new + beta_k * pk \n",
    "\n",
    "        rk = rk_new.copy()\n",
    "\n",
    "    \n",
    "\n",
    "    return xk, rk, i+1, False\n",
    "     \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteracion:  1\n",
      "n:  2\n",
      "k:  3\n",
      "xk[:3] [ 4.  -1.5]\n",
      "xk[-3:] [ 4.  -1.5]\n",
      "||rk||:  2.383e-14\n",
      "flag:  True\n",
      "Numero de condicion:  4.0\n",
      "-----------------------------------------\n",
      "Iteracion:  2\n",
      "n:  2\n",
      "k:  3\n",
      "xk[:3] [-5. -9.]\n",
      "xk[-3:] [-5. -9.]\n",
      "||rk||:  2.874e-12\n",
      "flag:  True\n",
      "Numero de condicion:  279.2\n",
      "-----------------------------------------\n",
      "Iteracion:  3\n",
      "n:  10\n",
      "k:  11\n",
      "xk[:3] [1. 1. 1.]\n",
      "xk[-3:] [1. 1. 1.]\n",
      "||rk||:  3.833e-17\n",
      "flag:  True\n",
      "Numero de condicion:  7.544\n",
      "-----------------------------------------\n",
      "Iteracion:  4\n",
      "n:  100\n",
      "k:  58\n",
      "xk[:3] [-1. -1. -1.]\n",
      "xk[-3:] [-1. -1. -1.]\n",
      "||rk||:  1.375e-07\n",
      "flag:  True\n",
      "Numero de condicion:  102.0\n",
      "-----------------------------------------\n",
      "Iteracion:  5\n",
      "n:  500\n",
      "k:  12\n",
      "xk[:3] [ 1. -1.  1.]\n",
      "xk[-3:] [-1.  1. -1.]\n",
      "||rk||:  7.606e-08\n",
      "flag:  True\n",
      "Numero de condicion:  22.91\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 6): \n",
    "    path = f'datosTarea02/matA_vecb{i}.npz'\n",
    "\n",
    "    A, b = load_data(path)\n",
    "    n = len(b)\n",
    "\n",
    "    print(\"Iteracion: \", i)\n",
    "    x0 = [0 for i in range(n)]\n",
    "    x0[0] = -5 \n",
    "    tol = (n * eps)**(1/2)\n",
    "\n",
    "    xk, rk, k, flag = gradiente_conjugado (A, b, x0, n, tol)\n",
    "\n",
    "    print(\"n: \", n)\n",
    "    print(\"k: \", k)\n",
    "    print(\"xk[:3]\", xk[:3])\n",
    "    print(\"xk[-3:]\", xk[-3:])\n",
    "    print(f\"||rk||: {np.linalg.norm(rk) : .4}\")\n",
    "    print(\"flag: \", flag)\n",
    "\n",
    "    condicion = get_condicion(A) \n",
    "\n",
    "    print(f\"Numero de condicion: {condicion : .4}\")\n",
    "    print(\"-----------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, compararemos los resultados con los obtenidos en el ejericico 2 de la tarea 2. \n",
    "\n",
    "Como comentarios generales podemos observar que el algoritmo implementado en esta tarea utiliza menos iteraciones para poder obtener los mismos resultados. \n",
    "\n",
    "En los primeros casos el contenido del vector xk son identicos, sin embargo, a partir del tercer caso, podemos observar una diferencia en la precisión del resultado, pues en la implementación de la tarea actual alcanzamos el valor de 1 o -1 según el caso, mientras que en la implementación de la tarea 2 se alcanzan valores cercanos a 1 o -1, pero no iguales en todos los casos. \n",
    "\n",
    "Podemos concluir que este algoritmo obtiene se desempeña mejor, en general, pues obtiene resultados más precisos y en menos iteraciones. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```\n",
    "\n",
    "\n",
    "```\n",
    "---\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tareas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
